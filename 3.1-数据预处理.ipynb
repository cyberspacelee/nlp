{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "机器学习中的特征类别：**连续型特征**和**离散型特征**。\n",
    "- 对于连续型特征，采用标准化和归一化等方法进行处理\n",
    "- 对于离散型特征，使用One-Hot(独热编码)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. One-Hot编码"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 什么是One-Hot编码\n",
    "One-Hot编码，又称为一位有效编码，主要是采用N位状态寄存器来对N个状态进行编码，每个状态都由他独立的寄存器位，并且在任意时候只有一位有效。\n",
    "One-Hot编码是分类变量作为二进制向量的表示。首先要求将分类值映射到整数值，然后，每个整数值被表示为二进制向量，除了整数的索引之外，它都是零值，它被标记为1。\n",
    "![](img/one-hot.png)\n",
    "### 1.2 为什么使用One-Hot编码\n",
    "One-Hot编码是将类别变量转换为机器学习算法易于利用的一种形式的过程。\n",
    "### 1.3 API及使用说明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import  OneHotEncoder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**API说明：**\n",
    "`OneHotEncoder(*, categories='auto', drop=None, sparse=True, dtype=<class 'numpy.float64'>, handle_unknown='error')`\n",
    "- categories：类别，可输入类别array或者自动从输入数据中获取；\n",
    "- drop：删除某个类别；\n",
    "- sparse：bool, default=True，如果设置为True则返回稀疏矩阵，否则返回一个数组；\n",
    "- handle_unknown：如果转换过程中出现未知的分类特性，是否引发错误或忽略(缺省情况是raise)。当该参数设置为“ignore”并且在转换过程中遇到一个未知类别时，该特性的one-hot编码列将全部为零。在反变换中，未知的类别将被表示为None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**方法：**\n",
    "- fit(X[, y])：传入待转换的X\n",
    "- fit_transform(X[, y])：传入待转换的X后，转换成one-hot编码\n",
    "- get_feature_names：返回特征name\n",
    "- inverse_transform(X)：one-hot编码转换成类别\n",
    "- transform(X)：利用fit过的类别，转换新的数据成one-hot编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OneHotEncoder()\n",
    "x = [['Male', 1], ['Female', 3], ['Female', 2]]\n",
    "enc.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 类别转one-hot编码\n",
    "# enc.transform([['Female', 1], ['Male', 4]]).toarray() 出现新的category[4]会报错\n",
    "enc.handle_unknown='ignore'\n",
    "enc.transform([['Female', 1], ['Male', 4]]).toarray() # 前两列表示性别男女，后面三列表示数字类别1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Male', 1],\n",
       "       [None, 2]], dtype=object)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot编码转换成类别\n",
    "enc.inverse_transform([[0, 1, 1, 0, 0],\n",
    "                       [0, 0, 0, 1, 0]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['gender_Female', 'gender_Male', 'group_1', 'group_2', 'group_3'],\n",
       "       dtype=object),\n",
       " array(['x0_Female', 'x0_Male', 'x1_1', 'x1_2', 'x1_3'], dtype=object))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 给特征添加name\n",
    "enc.get_feature_names(['gender', 'group']), enc.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 1., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 1., 0., 1., 0., 0.],\n",
       "       [0., 1., 1., 0., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 转换数字类别\n",
    "enc = OneHotEncoder(sparse = False)\n",
    "ans = enc.fit_transform([[0, 0, 3],\n",
    "                         [1, 1, 0],\n",
    "                         [0, 2, 1],\n",
    "                         [1, 0, 2]])\n",
    "ans "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 标准化/归一化\n",
    "标准化和归一化可以提高模型的精度和训练时的收敛速度。\n",
    "sklearn的preprocessing提供了可以满足需求的归一化方法。\n",
    "### 2.1 StandardScaler (标准归一化）\n",
    "标准化通过计算训练集中样本的均值和标准差，对每个特征单独进行中心化和缩放，使用变换方法对测试数据进行使用。\n",
    "标准化的计算方式是：\n",
    "$$X_{norm}=\\frac{X-X_{mean}}{X_{std}}$$\n",
    "数据集的标准化是许多机器学习估计器的一个常见要求，如果单个特征看起来不像标准正态分布数据，它们的性能可能会很差。\n",
    "#### 2.1.1 API\n",
    "sklearn标准化有两种实现方式：\n",
    "- 调用sklearn.preprocessing.scale()函数，sklearn.preprocessing.scale(X, axis=0, with_mean=True, with_std=True, copy=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理后的数据：\n",
      "[[-0.30151134 -1.60591014  0.4472136 ]\n",
      " [ 0.90453403  0.22941573  1.34164079]\n",
      " [-1.50755672  1.14707867 -0.4472136 ]\n",
      " [ 0.90453403  0.22941573 -1.34164079]]\n",
      "处理后数据的期望：[2.77555756e-17 4.16333634e-17 0.00000000e+00]\n",
      "处理后数据的标准差：[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "X = np.array([[ 1., -1.,  0.],\n",
    "               [ 2.,  1.,  1.],\n",
    "               [ 0.,  2., -1.],\n",
    "              [ 2.,  1., -2.]])\n",
    "X_scaled = preprocessing.scale(X)\n",
    "print('处理后的数据：\\n{}\\n处理后数据的期望：{}\\n处理后数据的标准差：{}'.format(X_scaled, X_scaled.mean(axis=0), X_scaled.std(axis=0)))\n",
    "# axis 用来计算平均值和标准差的轴。如果是0，独立标准化每个特征，否则(如果是1)标准化每个样本。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 实例化一个sklearn.preprocessing.StandardScaler()，sklearn.preprocessing.StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "\n",
    "**API说明：**\n",
    "- copy：如果为false,就会用归一化的值替代原来的值，如果被标准化的数据不是np.array或scipy.sparse CSR matrix, 原来的数据还是被copy而不是被替代\n",
    "- with_mean：boolean类型，默认为True，表示将数据均值规范到0\n",
    "- with_std：boolean类型，默认为True，表示将数据方差规范到1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**方法：**\n",
    "- fit(x[,y])：计算X中的均值和标准差，以便后面使用\n",
    "- fit_transform(x[,y])：对X做标准化，映射为0均值单位方差的正态分布\n",
    "- transform(x[,y])：用存有均值和方差的标准化方法对x做标准化\n",
    "- get_params()：get parameters of the estimator\n",
    "- set_params()：set parameters of the estimator\n",
    "- inverse_transform(X)：将数据回退到原始表示形式\n",
    "- partial_fit(X[, y])：为以后的缩放在线计算均值和标准差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.30151134, -1.60591014,  0.4472136 ],\n",
       "       [ 0.90453403,  0.22941573,  1.34164079],\n",
       "       [-1.50755672,  1.14707867, -0.4472136 ],\n",
       "       [ 0.90453403,  0.22941573, -1.34164079]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X)\n",
    "scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.30151134, -1.60591014,  0.4472136 ],\n",
       "       [ 0.90453403,  0.22941573,  1.34164079],\n",
       "       [-1.50755672,  1.14707867, -0.4472136 ],\n",
       "       [ 0.90453403,  0.22941573, -1.34164079]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled = scaler.transform(X)         \n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., -1.,  0.],\n",
       "       [ 2.,  1.,  1.],\n",
       "       [ 0.,  2., -1.],\n",
       "       [ 2.,  1., -2.]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.inverse_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 MinMaxScaler (最小最大值归一化）\n",
    "公式：\n",
    "$$\n",
    "\\begin{array}{r}\n",
    "X_{s t d}=\\frac{X-X \\cdot \\min (a x i s=0)}{X \\cdot \\max (a x i s=0)-X \\cdot \\min (a x i s=0)} \\\\\n",
    "X_{\\text {scaled}}=X_{s t d} \\times (\\max -\\min )+\\min\n",
    "\\end{array}\n",
    "$$\n",
    "转换后范围：[0,1]\n",
    "#### 2.2.1 API\n",
    "sklearn.preprocessing.MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xmin=[-1.  2.],Xmax=[ 2. 18.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "data = [[-1, 2], \n",
    "        [-0.5, 6], \n",
    "        [2, 10], \n",
    "        [1, 18]]\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data)\n",
    "print('Xmin={},Xmax={}'.format(scaler.data_min_, scaler.data_max_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        ],\n",
       "       [0.16666667, 0.25      ],\n",
       "       [1.        , 0.5       ],\n",
       "       [0.66666667, 1.        ]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.transform([[2, 2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 MaxAbsScaler (最大绝对值归一化）\n",
    "按其最大绝对值缩放每个特征\n",
    "$$X_{scaled}=\\frac{X}{|X_{max}|}$$\n",
    "#### 2.3.1 API\n",
    "sklearn.preprocessing.MaxAbsScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.5, -0.5,  0. ],\n",
       "        [ 1. ,  0.5,  0.5],\n",
       "        [ 0. ,  1. , -0.5],\n",
       "        [ 1. ,  0.5, -1. ]]),\n",
       " array([[ 1., -1.,  0.],\n",
       "        [ 2.,  1.,  1.],\n",
       "        [ 0.,  2., -1.],\n",
       "        [ 2.,  1., -2.]]))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "transformer = MaxAbsScaler().fit(X)\n",
    "transformer.transform(X), X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 RobustScaler (鲁棒归一化）\n",
    "#### 2.4.1 API\n",
    "sklearn.preprocessing.RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
