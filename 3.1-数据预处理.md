机器学习中的特征类别：**连续型特征**和**离散型特征**。
- 对于连续型特征，采用标准化和归一化等方法进行处理
- 对于离散型特征，使用One-Hot(独热编码)

## 1. One-Hot编码

### 1.1 什么是One-Hot编码
One-Hot编码，又称为一位有效编码，主要是采用N位状态寄存器来对N个状态进行编码，每个状态都由他独立的寄存器位，并且在任意时候只有一位有效。
One-Hot编码是分类变量作为二进制向量的表示。首先要求将分类值映射到整数值，然后，每个整数值被表示为二进制向量，除了整数的索引之外，它都是零值，它被标记为1。
![](img/one-hot.png)
### 1.2 为什么使用One-Hot编码
One-Hot编码是将类别变量转换为机器学习算法易于利用的一种形式的过程。
### 1.3 API及使用说明


```python
from sklearn.preprocessing import  OneHotEncoder 
```

**API说明：**
`OneHotEncoder(*, categories='auto', drop=None, sparse=True, dtype=<class 'numpy.float64'>, handle_unknown='error')`

- categories：类别，可输入类别array或者自动从输入数据中获取；
- drop：删除某个类别；
- sparse：bool, default=True，如果设置为True则返回稀疏矩阵，否则返回一个数组；
- handle_unknown：如果转换过程中出现未知的分类特性，是否引发错误或忽略(缺省情况是raise)。当该参数设置为“ignore”并且在转换过程中遇到一个未知类别时，该特性的one-hot编码列将全部为零。在反变换中，未知的类别将被表示为None

**方法：**
- fit(X[, y])：传入待转换的X
- fit_transform(X[, y])：传入待转换的X后，转换成one-hot编码
- get_feature_names：返回特征name
- inverse_transform(X)：one-hot编码转换成类别
- transform(X)：利用fit过的类别，转换新的数据成one-hot编码


```python
enc = OneHotEncoder()
x = [['Male', 1], ['Female', 3], ['Female', 2]]
enc.fit(X)
```


    OneHotEncoder()


```python
enc.categories_
```


    [array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]


```python
# 类别转one-hot编码
# enc.transform([['Female', 1], ['Male', 4]]).toarray() 出现新的category[4]会报错
enc.handle_unknown='ignore'
enc.transform([['Female', 1], ['Male', 4]]).toarray() # 前两列表示性别男女，后面三列表示数字类别1-3
```


    array([[1., 0., 1., 0., 0.],
           [0., 1., 0., 0., 0.]])


```python
# one-hot编码转换成类别
enc.inverse_transform([[0, 1, 1, 0, 0],
                       [0, 0, 0, 1, 0]]) 
```


    array([['Male', 1],
           [None, 2]], dtype=object)


```python
# 给特征添加name
enc.get_feature_names(['gender', 'group']), enc.get_feature_names()
```


    (array(['gender_Female', 'gender_Male', 'group_1', 'group_2', 'group_3'],
           dtype=object),
     array(['x0_Female', 'x0_Male', 'x1_1', 'x1_2', 'x1_3'], dtype=object))


```python
# 转换数字类别
enc = OneHotEncoder(sparse = False)
ans = enc.fit_transform([[0, 0, 3],
                         [1, 1, 0],
                         [0, 2, 1],
                         [1, 0, 2]])
ans 
```


    array([[1., 0., 1., 0., 0., 0., 0., 0., 1.],
           [0., 1., 0., 1., 0., 1., 0., 0., 0.],
           [1., 0., 0., 0., 1., 0., 1., 0., 0.],
           [0., 1., 1., 0., 0., 0., 0., 1., 0.]])

## 2. 标准化/归一化
标准化和归一化可以提高模型的精度和训练时的收敛速度。
sklearn的preprocessing提供了可以满足需求的归一化方法。
### 2.1 StandardScaler (标准归一化）
标准化通过计算训练集中样本的均值和标准差，对每个特征单独进行中心化和缩放，使用变换方法对测试数据进行使用。
标准化的计算方式是：
$$X_{norm}=\frac{X-X_{mean}}{X_{std}}$$
数据集的标准化是许多机器学习估计器的一个常见要求，如果单个特征看起来不像标准正态分布数据，它们的性能可能会很差。
#### 2.1.1 API
sklearn标准化有两种实现方式：
- 调用sklearn.preprocessing.scale()函数，sklearn.preprocessing.scale(X, axis=0, with_mean=True, with_std=True, copy=True)


```python
from sklearn import preprocessing
import numpy as np
X = np.array([[ 1., -1.,  0.],
               [ 2.,  1.,  1.],
               [ 0.,  2., -1.],
              [ 2.,  1., -2.]])
X_scaled = preprocessing.scale(X)
print('处理后的数据：\n{}\n处理后数据的期望：{}\n处理后数据的标准差：{}'.format(X_scaled, X_scaled.mean(axis=0), X_scaled.std(axis=0)))
# axis 用来计算平均值和标准差的轴。如果是0，独立标准化每个特征，否则(如果是1)标准化每个样本。
```

    处理后的数据：
    [[-0.30151134 -1.60591014  0.4472136 ]
     [ 0.90453403  0.22941573  1.34164079]
     [-1.50755672  1.14707867 -0.4472136 ]
     [ 0.90453403  0.22941573 -1.34164079]]
    处理后数据的期望：[2.77555756e-17 4.16333634e-17 0.00000000e+00]
    处理后数据的标准差：[1. 1. 1.]


- 实例化一个sklearn.preprocessing.StandardScaler()，sklearn.preprocessing.StandardScaler(copy=True, with_mean=True, with_std=True)

**API说明：**
- copy：如果为false,就会用归一化的值替代原来的值，如果被标准化的数据不是np.array或scipy.sparse CSR matrix, 原来的数据还是被copy而不是被替代
- with_mean：boolean类型，默认为True，表示将数据均值规范到0
- with_std：boolean类型，默认为True，表示将数据方差规范到1

**方法：**
- fit(x[,y])：计算X中的均值和标准差，以便后面使用
- fit_transform(x[,y])：对X做标准化，映射为0均值单位方差的正态分布
- transform(x[,y])：用存有均值和方差的标准化方法对x做标准化
- get_params()：get parameters of the estimator
- set_params()：set parameters of the estimator
- inverse_transform(X)：将数据回退到原始表示形式
- partial_fit(X[, y])：为以后的缩放在线计算均值和标准差


```python
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler().fit(X)
scaler.fit_transform(X)
```


    array([[-0.30151134, -1.60591014,  0.4472136 ],
           [ 0.90453403,  0.22941573,  1.34164079],
           [-1.50755672,  1.14707867, -0.4472136 ],
           [ 0.90453403,  0.22941573, -1.34164079]])


```python
X_scaled = scaler.transform(X)         
X_scaled
```


    array([[-0.30151134, -1.60591014,  0.4472136 ],
           [ 0.90453403,  0.22941573,  1.34164079],
           [-1.50755672,  1.14707867, -0.4472136 ],
           [ 0.90453403,  0.22941573, -1.34164079]])


```python
scaler.inverse_transform(X_scaled)
```


    array([[ 1., -1.,  0.],
           [ 2.,  1.,  1.],
           [ 0.,  2., -1.],
           [ 2.,  1., -2.]])

### 2.2 MinMaxScaler (最小最大值归一化）
公式：
$$
\begin{array}{r}
X_{s t d}=\frac{X-X \cdot \min (a x i s=0)}{X \cdot \max (a x i s=0)-X \cdot \min (a x i s=0)} \\
X_{\text {scaled}}=X_{s t d} \times (\max -\min )+\min
\end{array}
$$
转换后范围：[0,1]
#### 2.2.1 API
sklearn.preprocessing.MinMaxScaler


```python
from sklearn.preprocessing import MinMaxScaler
data = [[-1, 2], 
        [-0.5, 6], 
        [2, 10], 
        [1, 18]]
scaler = MinMaxScaler()
scaler.fit(data)
print('Xmin={},Xmax={}'.format(scaler.data_min_, scaler.data_max_))
```

    Xmin=[-1.  2.],Xmax=[ 2. 18.]

```python
scaler.transform(data)
```


    array([[0.        , 0.        ],
           [0.16666667, 0.25      ],
           [1.        , 0.5       ],
           [0.66666667, 1.        ]])


```python
scaler.transform([[2, 2]])
```


    array([[1., 0.]])

### 2.3 MaxAbsScaler (最大绝对值归一化）
按其最大绝对值缩放每个特征
$$X_{scaled}=\frac{X}{|X_{max}|}$$

#### 2.3.1 API
sklearn.preprocessing.MaxAbsScaler

```python
from sklearn.preprocessing import MaxAbsScaler
transformer = MaxAbsScaler().fit(X)
transformer.transform(X), X
```


    (array([[ 0.5, -0.5,  0. ],
            [ 1. ,  0.5,  0.5],
            [ 0. ,  1. , -0.5],
            [ 1. ,  0.5, -1. ]]),
     array([[ 1., -1.,  0.],
            [ 2.,  1.,  1.],
            [ 0.,  2., -1.],
            [ 2.,  1., -2.]]))

### 2.4 RobustScaler (鲁棒归一化）
#### 2.4.1 API
sklearn.preprocessing.RobustScaler()

